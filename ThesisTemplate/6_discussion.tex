\section{Discussion}
\label{sec:disc}
%introduction 
In this section we first discuss the current challenges for a Job Recommender System (JRS) for 
welfare beneficiaries (\ref{ssec:jrswb}) in order to answer the main Research Question~\ref{rq:mrq}: 
\begin{itemize}
	\item[] \em Can a Content-Based Recommender System based on matching job openings to welfare beneficiaries provide recommendations of a quality comparable to human customer managers?
\end{itemize}
Thereafter alternative approaches that can make a JRS possible are discussed (\ref{ssec:learnings}). 

%Current Challenges with a Job Recommender System for Welfare Beneficiaries
\subsection{Current Challenges with a Job Recommender System for Welfare Beneficiaries}
\label{ssec:jrswb}
%introduction
Based on the findings we discuss in this part the current challenges with a JRS for welfare beneficiaries.
The objective of this research was to study the feasibility of a JRS especially designed for welfare beneficiaries. 
The results presented in section \ref{sec:rslts} showed that it is difficult to recommend jobs with the available data.
This can in part be explained by the number of observations and the quality of them.

%How representative is the data?
\noindent
\textbf{Representativity Data}\\
The provided dataset contained 8,265 observations that were collected over a time period of five years in which on average 41,361 households monthly received welfare benefits in the municipality of Amsterdam.
In total 75,640 unique households received welfare benefits in this period.
Considering these figures the real number of occurred job matches is most likely to be in order of multitudes higher.
Therefore it can be questioned how representative the data is, because it is thought that it only represents a small subset of the true number of job matches that took place in that period.  
The small number of documented job matches can be attributed to a combination of factors.
First, not all welfare beneficiaries are obliged to apply for jobs.
Second, not all welfare beneficiaries have applied for jobs listed by the WSP.
Third and most important factor is that the registration by the customer managers can be improved.
According to domain experts there is a tendency to only register the most promising job matches.
This could also explain the observed overrepresentation of positive labels since a class imbalance towards the negative labels would rather be expected.
The reasoning behind this is that it is assumed that people apply for multiple jobs when they receive welfare benefits for a long period. 
Another issue with the registration is that when a job match gets documented in more than half of the cases (54\%) there is eventually no feedback received from the employer on what the outcome was.

Adding all these factors together it can be argued that the data is not representative for the total population of welfare beneficiaries within the city of Amsterdam. 

%cold-start problem and clustering
\noindent
\textbf{The Cold-Start Problem}\\
The cold start problem is an issue particular associated with JRS. In our case this problem is amplified by the preselection bias with 76\% of the observations being 1-to-1 relations (a user applies only once for a job, and for a job is applied only once). 
Within the municipality of Amsterdam welfare beneficiaries are placed in specific teams based on their opportunities in the labor market.
It is assumed that this segmentation pattern can also be found in the data.
Therefore it is hypothesized that it is possible to segment the welfare beneficiaries in two general categories.
The first category consists of people who can easily find a job. 
It is expected that this group receives welfare benefits for a short time period and that they apply only once or just a couple of times for a job with mostly positive outcomes. 
The second category contains people for whom it is hard to find a job. 
This group is expected to receive welfare benefits over a long period of time and therefore will apply for a lot of jobs with predominantly negative results.

Attempts to cluster the users in two or more clusters did not deliver promising results.
This could be explained by one of the following four reasons: 1) there are no distinct user groups, 2) there are far more user groups than tested (400+), 3) the user features are not informative, or 4) the data is biased towards the welfare beneficiaries with the best opportunities on the labor market.
The domain experts that were consulted for this research indicated that welfare beneficiaries who are placed in the customer manager team with the best job opportunities are predominantly represented in the data.  
This is interesting because it could explain that due to the preselection bias only people from that team have made it into the dataset, and since this group commonly matches positively with job openings this causes the class imbalance.

If there are two or more groups of welfare beneficiaries the JRS should take that into consideration when learning to predict job matching outcomes, otherwise the JRS is optimized in recommending job matches for one group of users.

\mynote[author=Harrie]{Je begint deze sectie over het cold-start probleem, maar eindigt hem over preselection bias. Het cold-start probleem word niet meer besproken na de eerste zinnen, en het bias probleem lijkt meer bij de vorige sectie te passen.}

%Why do the user features have no predictive power?
\noindent
\textbf{User Features}\\
Another interesting finding presented in section~\ref{ssec:ir} is that job matches can be more accurately predicted when all user features are left out.  
Two plausible causes for why this occurs are: 1) the user features do not make a difference for job matching, or 2) the user features are not informative.
% \mynote[author=Harrie]{De eerste reden word niet meer genoemd, er mist een uitleg voor waarom de tweede reden het meest aannemelijk is.}

According to the consulted domain experts the user characteristics such as education, age and motivation are essential for matching users to job openings. 
This claim is further supported by JRS literature \cite{kenthapadi2017personalized, T.Al-Otaibi2012ASystems, Zheng2012JobSurvey, hong2013job}.
It can therefore be argued that it is improbable that the user features do not matter for a job match. 

A likely explanation for the second reason is that this is caused by the way how the user features are documented.
Before the data enters the JRS there are a couple of transfer and interpretation moments. 
The first is the verbal transfer from the welfare beneficiary to the customer manager.
The second takes place when the customer manager enters the information into the system.
The third is the extraction of the data from the system for the researcher of the JRS.
And finally the researcher applies feature engineering and other transformations before inputting the data into a machine learning model.
With every transfer bias and noise can arise, especially since at the transfer moments often assumptions need to be made that can possibly introduce bias.
It is thought that the first two transfer moments are most determining for the quality of the data, but they also introduce most of the bias and noise. The most probable cause is that there are various registration approaches between the different customer manager teams and also between the individual customers managers within the same team. 
Furthermore, over the years there have been changes appended in the documentation procedures, causing that fields in the system that had to be filled in a certain period were not filled  in another period.
Last and probably the most important factor is that a lot of the registered information is by nature highly subjective with many possible interpretations resulting in the main source of bias in the data. 
On the other hand, it can also be imagined that the researcher of the JRS did introduce bias and noise.
For example by the preselection of attributes based on heuristics prior to the retrieval from the system/database is a moment that bias can have been imported into the data.
Moreover, during the feature engineering process also bias and noise can have been entered into the data.

The finding that in our case the user features have no predictive power can presumably be attributed to a combination of the aforementioned factors. 

%Temporal dependency 
\noindent
\textbf{Temporal Aspects} \\
Finally the data is assumed to exhibit a time dependency.
Hiring criteria change over time, and according to consulted domain experts of the municipality of Utrecht for welfare beneficiaries these should be updated at least every six months. 
Moreover it was found that all approaches to a JRS described in literature model temporal aspects  \cite{kenthapadi2017personalized, T.Al-Otaibi2012ASystems, Zheng2012JobSurvey, hong2013job}.
During and in the aftermath of the financial crisis job hiring criteria became increasingly strict, but when the economy recovered and the labor market became tighter the hiring criteria started to lower. 
The thought is that this cycle affects welfare beneficiaries more than other job seekers because they are often at the lower end of the labor market.
This time-bound labor market dynamics can explain why the same types of jobs can have very different hiring criteria depending on the time they were posted.
This makes it harder for the machine learning models to identify and generalize patterns.

A possible solution would be to model the time dependency using a sliding window or another technique, however for this research this could not be applied because then the number of observations would get too low.

%Summary/Conclusion
\noindent
\textbf{Answering the Main Research Question}\\
The mediocre results of the JRS can possibly also be contributed to the methods that were chosen or the features that were selected. 
However, it appears to be more likely that it can be attributed to the bias and noise that reside in the data.
Therefore it can be argued that in our case it is currently not feasible to build a JRS with the available data in combination with the applied methods. 

%Answer to the Main Research Question
In conclusion to answer the main Research Question~\ref{rq:mrq}: it was found that for our study based on the available data it is unlikely that the outcomes of a content-based recommender system can match job openings with welfare beneficiaries in a comparable way as human customer managers. 

%Alternative Approach
\subsection{Alternative Approach}
\label{ssec:learnings}

%Intro
In Data Science there is an emphasis on data, and consequently the quality of the available data determines more than other things the success of a Data Science research project.
In case of this research the current available data turned out to be not yet ready to build a complex JRS. 
In this part it is described what can be done to make a JRS possible in the future.

%Data Quantity
\noindent
\textbf{Data Quantity}\\
Regarding the representativity of the data, the cold-start problem and the temporal aspects it was found that the availability of enough data prior to researching the feasibility of a JRS is a prerequisite.
What is enough data?
There is no absolute answer on that question. 
However, what is known is that other JRS systems have millions of observations at their disposal \cite{kenthapadi2017personalized, T.Al-Otaibi2012ASystems, Zheng2012JobSurvey, hong2013job}.
In our case the number of documented job matching outcomes were presumed to be too low. 
This can be increased by a structured and improved registration discipline.

%Conclusion/benefits
More data does not automatically improve the representativity of the data, it is also important that all segmented groups of users are as far as possible represented equally in the data.
The availability of more data can tackle the cold-start problem directly or make the use of clustering algorithms more effective. 
Finally, a high quantity of data enables the modelling of the temporal aspects that are thought to be present in the data.

%Data Quality
\noindent
\textbf{Data Quality}\\
The fact that user features are not informative for the tested models is attributed to the data quality. 
Therefore the second prerequisite for a JRS is better data quality.
What is good quality data?
In general good quality data is perceived to meet at least the following requirements: completeness, consistency, accuracy, time stamped, and complying with the industry standards. 
In our case the quality of the data did not adhere to these characteristics: there are too many user features and too many options and fields to document user information, which are moreover also inconsistently used. 

One the causes found is that the quality of the data is negatively influenced by the fact that the procedures concerning the data registration have been altered in certain periods of time. 
To improve the quality of the data consistent registration is key.
This can be reached by the alignment of the data governance across the different teams and customer managers.

The data quality is also affected by the bias and noise that is introduced at the various transfer moments during the registration.
Excluding all bias is impossible, but this can be limited by the aligned data governance in the form of highly structured recording procedures and simplified user profiles.
Simplified user profiles imply the reduction the number of user attributes and the free text fields. 
An additional advantage of implementing this is that this will also lower the administrative burden for the customer managers.
The documentation of only the necessary user attributes can also be seen as a contribution to the adherence of the privacy by design principles. 
The premise is that a better data quality leads to data that is informative.

%Final part
% \noindent
% \textbf{Nice Title}\\
Currently the city of Amsterdam is taking steps to improve the quantity and quality of their data. 
Taking notion of this the artifacts that were found in the data convey the message not to focus too much on the present but also consider the future.
This requires to think not only about the question “where do we need the data for now” but also “how do we organize our data in such a way that it also usable for future methods?”

When the prerequisites for the data are met the implementation of JRS becomes feasible.
This will take time, maybe years, but it is probably a worthwhile  investment keeping in mind that proper documented data can be used for far more purposes than job recommendation only.
When there is enough quantity and quality of the data it is advised to redo this research. 

\mynote[author=Harrie]{Niet alle problemen besproken in de vorige sectie worden hier aangepakt, bijvoorbeeld, ik verwachte een oplossing voor de negative/positive label ratio oftewel een deel van de preselection bias. Kijk of je concrete oplossingen kan bedenken en voeg die toe.}

