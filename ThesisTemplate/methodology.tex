\section{Methodology}
\label{sec:meth}


\subsection{Description of the data}
Data verzameling en beschrijving van de data

% Hoe is de data verzameld, en hoe heb jij die data verkregen?
% Wat staat er in de data? Niet alleen maar een technisch verhaal, maar ook inhoudelijk. DE lezer moet een goed idee krijgen over de technische inhoud en wat het betekent.

% \pagebreak
% \subsection{Wat plotjes en tabelletjes}

% Zie het IPython Notebook \url{PandasAndLatex.ipynb} voor de code om vanuit pandas een poltje op te slaan en een dataframe als tabel op te slaan. Het werkt ideaal! 

% De interrupties van Wilders staan beschreven in Figure~\ref{fig:wilders} en Tabel~~\ref{tab:Wilders}.


% \begin{figure}
% \begin{center}
% \includegraphics[width=\linewidth]{WildersPlot.png}
% \caption{\label{fig:wilders} Aantal interrupties van Wilders in de Tweede Kamer door de tijd (periode 2012-2016).}
% \end{center}
% \end{figure}


% \pagebreak

% \begin{table}[h]
% \begin{footnotesize}
% \input{WildersTable}
% \end{footnotesize}
% \caption{\label{tab:Wilders} Door wie werd Wilders onderbroken en hoe vaak per debat.}
% \end{table}



\subsection{Methods}
Hoe je je vraag gaat beantwoorden.
% Dit is de langste sectie van je scriptie. 
% Als iets erg technisch wordt kan je een deel naar de Appendix verplaatsen. 
% Probeer er een lopend verhaal van te maken.
% Het is heel handig dit ook weer op te delen nav je deelvragen:

% \subsubsection{RQ1}

% \subsubsection{RQ2}

\subsubsection{Clustering}
The hypothesis is that there are different strata within the welfare beneficiaries and job vacancies. 
The welfare beneficiaries can for example be classified based on education level, age, work experience and be placed in distinct strata.
Furthermore it can be argued that an individual group of welfare beneficiaries can be linked to a particular set of job vacancies which are best matching. 
If it can be proven that it is plausible to realize stratification this can simplify the recommendation objective. 
A welfare beneficiary is, based on its features, allocated to a strata of welfare beneficiaries and connected to one or more sets of job vacancies. 
The objective here is to predict to which strata a welfare beneficiary belongs to that is linked to a particular set of job vacancies. 

The welfare beneficiary and job vacancy strata are unlabeled thus there are only two ways to stratify the data: 1) manual annotation based on domain knowledge, or 2) apply a unsupervised clustering algorithm.
The first way is labor intensive and time consuming due to the number of records, and because of time constraints is this method not feasible. 
For the second way there are multiple algorithm choices possible, however the data is mainly categorical with only a few numerical columns what limits the possibilities. 
Two unsupervised clustering algorithms are investigated: K-Prototypes which can handle a combination of numerical and categorical data \cite{huang1997clustering}, and K-Modes which deals only with categorical data \cite{huang1997clustering, huang1998extensions}.
The find the best cluster size (K) a limited but ascending number of K’s are explored, and evaluated by plotting the cost function (Elbow plot) and by adding the clusters to features and determine if the prediction function improves.

\subsubsection{Content-Based Recommender}
For the content-based recommender six different types of algorithms will be explored: 1) Nearest Neighbors, 2) K-Nearest Neighbors Classification, 3) Random Forest Classifier, 4) Binary Logistic Regression, 5) Linear Support Vector Classification, and 6) Neural Network. 
The first algorithm that is implemented is Nearest Neighbors, this algorithm is relatively straightforward and the outcomes are easy to assess 
\cite{aggarwal2016recommender}. 
The results of Nearest Neighbors serves as a benchmark to which the other algorithms are compared to. 
An extension of Nearest Neighbors is K-Nearest Neighbors Classification which is an algorithm that computes the class label from a majority vote of the K nearest neighbors \cite{NearestNeighbors}. 
An important difference between the two is that Nearest Neighbors is an unsupervised algorithm, while K-Nearest Neighbors Classification is supervised because during the training a set of correct class labels is provided.
The K-Nearest Neighbors Classification algorithm can therefore predict binary labels.
The Random Forest Classifier is a ruled based algorithm that is constructed out of multiple decision trees on randomly selected data samples \cite{breiman2001random}.
It predicts a class label by getting the predictions of each tree and selecting the best label by means of voting.
The algorithm learns rules that determine a class label, or in other words it learns which combination of features constitutes to a particular class label.

As fourth a regression-based model is implemented.
This type of model is explored because it learns a linear combination of features to predict a certain outcome. 
The learning objective is to predict a binary label (0 : no match, 1: match). 
From literature it can be derived that the binary logistic regression is particularly suitable for this problem \cite{aggarwal2016recommender}. 
Another often applied algorithm in case of binary ratings are support vector machines (SVM) \cite{burges1998tutorial}. 
This approach is similar to logistic regression with as main difference that SVM’s use a hinge loss rather then a logit function.
The advantage of the hinge loss is that it enables the SVM to learn non-linear patrons in the data. 
There is a myriad of subtypes within the family of SVM’s. For  this research the implementation of a linear support vector classification (SVC) is investigated because it is applicable for binary classification problems \cite{fan2008liblinear}. 

Singhal et al (2017) surveyed the use of Neural Networks for recommender systems \cite{singhal2017use}, and their research shows that Neural Networks are currently used in both collaborative filtering and in content-based filtering. 
The implementation of a Neural Network is researched because it excels in learning complex non-linear relationships between variables, and due to this trait it can learn patterns that humans are unable to identify. 
